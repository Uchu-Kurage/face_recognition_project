import json
import os
import sys
from datetime import datetime

def load_scan_results(json_path='scan_results.json'):
    if not os.path.exists(json_path):
        return None
    with open(json_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def create_story(person_name, period="All Time", focus="Balance", bgm_enabled=False, json_path='scan_results.json', output_playlist_path='story_playlist.json'):
    results = load_scan_results(json_path)
    if not results or person_name not in results.get("people", {}):
        print(f"Error: No data found for {person_name}")
        return

    video_map = results["people"][person_name]
    metadata = results.get("metadata", {})
    all_clips = []

    # Flatten the results into a list of clips with metadata
    for video_path, detections in video_map.items():
        # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        month = metadata.get(video_path, {}).get('month', 'unknown')
        if period != "All Time":
            if period.count("-") == 1: # YYYY-MM
                if month != period: continue
            else: # YYYY
                if month.split("-")[0] != period: continue

        for det in detections:
            all_clips.append({
                "video_path": video_path,
                "t": det["t"],
                "happy": det.get("happy", 0),
                "visual_score": det.get("visual_score", 5.0),
                "vibe": det.get("vibe", "ç©ã‚„ã‹"),
                "timestamp": det.get("timestamp", ""),
                "overlay_text": "" # å¾Œã§è¿½åŠ 
            })

    if not all_clips:
        print(f"Error: No clips found for {person_name}")
        return

    # Sort by timestamp first
    try:
        all_clips.sort(key=lambda x: datetime.strptime(x["timestamp"], '%Y-%m-%d %H:%M:%S') if x["timestamp"] else datetime.min)
    except:
        pass

    # ã™ã§ã«ä½¿ã£ãŸã‚·ãƒ¼ãƒ³ã€å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã€æ—¥ä»˜ã‚’è¨˜éŒ²ã™ã‚‹
    used_scenes = set() # (video_path, t) ã‚’è¨˜éŒ²
    used_videos = set()
    used_dates = set()

    import random

    def pick_unique(candidates, count, key_func, reverse=True):
        """é‡è¤‡ã‚’é¿ã‘ã¤ã¤ã€ä¸Šä½å€™è£œã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã™ã‚‹ã€‚"""
        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_cands = sorted(candidates, key=key_func, reverse=reverse)
        
        # å€™è£œãƒ—ãƒ¼ãƒ«ã‚’åºƒã’ã‚‹ï¼ˆå¿…è¦ãªæ•°ã®5å€ç¨‹åº¦ã¾ã§ï¼‰
        pool_size = min(len(sorted_cands), count * 5)
        pool = sorted_cands[:pool_size]
        
        # çµ¶å¯¾ã«åŒã˜ã‚·ãƒ¼ãƒ³ã¯é¸ã°ãªã„ (STRICT)
        pool = [c for c in pool if (c["video_path"], c["t"]) not in used_scenes]
        
        picked = []
        
        # Phase 1: æœªä½¿ç”¨ã®æ—¥ä»˜ & æœªä½¿ç”¨ã®ãƒ“ãƒ‡ã‚ª ã‹ã‚‰é¸ã¶ (ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³å„ªå…ˆ)
        p1 = [c for c in pool if c["video_path"] not in used_videos and c["timestamp"].split(" ")[0] not in used_dates]
        random.shuffle(p1)
        for c in p1:
            if len(picked) >= count: break
            picked.append(c)
            used_scenes.add((c["video_path"], c["t"]))
            used_videos.add(c["video_path"])
            used_dates.add(c["timestamp"].split(" ")[0])
        
        # Phase 2: æœªä½¿ç”¨ã®ãƒ“ãƒ‡ã‚ª ã‹ã‚‰é¸ã¶ (æ—¥ä»˜é‡è¤‡ã¯è¨±å®¹)
        if len(picked) < count:
            p2 = [c for c in pool if c["video_path"] not in used_videos and (c["video_path"], c["t"]) not in used_scenes]
            random.shuffle(p2)
            for c in p2:
                if len(picked) >= count: break
                picked.append(c)
                used_scenes.add((c["video_path"], c["t"]))
                used_videos.add(c["video_path"])
                used_dates.add(c["timestamp"].split(" ")[0])

        # Phase 3: ãƒ“ãƒ‡ã‚ª/æ—¥ä»˜é‡è¤‡ã‚’è¨±å®¹ã—ã¦é¸ã¶ (ãŸã ã—ã‚·ãƒ¼ãƒ³é‡è¤‡ã¯çµ¶å¯¾ã«NG)
        if len(picked) < count:
            p3 = [c for c in pool if (c["video_path"], c["t"]) not in used_scenes]
            random.shuffle(p3)
            for c in p3:
                if len(picked) >= count: break
                picked.append(c)
                used_scenes.add((c["video_path"], c["t"]))
                        
        return picked

    # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’4ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²
    total_count = len(all_clips)
    idx_ki = max(1, int(total_count * 0.2))
    idx_sho = max(idx_ki + 1, int(total_count * 0.65))
    idx_ten = max(idx_sho + 1, int(total_count * 0.9))

    ki_segment = all_clips[:idx_ki]
    sho_segment = all_clips[idx_ki:idx_sho]
    ten_segment = all_clips[idx_sho:idx_ten]
    ketsu_segment = all_clips[idx_ten:]

    # Focus ã®æ­£è¦åŒ– (UIã¯æ—¥æœ¬èªã€å†…éƒ¨ã¯è‹±èªã§åˆ¤å®šã—ã¦ã„ãŸãŸã‚)
    focus_map = {
        "ãƒãƒ©ãƒ³ã‚¹": "Balance",
        "ç¬‘é¡”": "Smile",
        "å‹•ã": "Active",
        "æ„Ÿå‹•": "Emotional"
    }
    focus = focus_map.get(focus, focus) # æ—¥æœ¬èªãªã‚‰è‹±èªã«ã€ãã†ã§ãªã‘ã‚Œã°ãã®ã¾ã¾

    # Focusã«å¿œã˜ãŸé¸æŠãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ã®åˆ‡ã‚Šæ›¿ãˆ
    def get_key_func(part):
        if focus == "Smile":
            # ç¬‘é¡”ã‚¹ã‚³ã‚¢å„ªå…ˆ
            return lambda x: x["happy"]
            
        elif focus == "Active":
            # ã‚¨ãƒãƒ«ã‚®ãƒƒã‚·ãƒ¥å„ªå…ˆã€ãªã‘ã‚Œã°Visual
            return lambda x: (x["vibe"] == "ã‚¨ãƒãƒ«ã‚®ãƒƒã‚·ãƒ¥", x["visual_score"])
            
        elif focus == "Emotional":
            # æ„Ÿå‹•çš„å„ªå…ˆã€ãªã‘ã‚Œã°ç©ã‚„ã‹ + Visual
            return lambda x: (x["vibe"] == "æ„Ÿå‹•çš„", x["visual_score"])
            
        else: # Balance (Default)
            if part == "èµ·": return lambda x: (x["vibe"] == "ç©ã‚„ã‹", x["visual_score"])
            elif part == "æ‰¿": return lambda x: x["visual_score"]
            elif part == "è»¢": return lambda x: x["happy"]
            elif part == "çµ": return lambda x: (x["vibe"] == "ç©ã‚„ã‹", x["visual_score"])

    # [èµ·] Intro: 2 clips
    ki = pick_unique(ki_segment, 2, get_key_func("èµ·"))

    # [æ‰¿] Development: 10 clips
    sho = pick_unique(sho_segment, 10, get_key_func("æ‰¿"))

    # [è»¢] Twist/Climax: 6 clips
    ten = pick_unique(ten_segment, 6, get_key_func("è»¢"))

    # [çµ] Conclusion: 2 clips
    ketsu = pick_unique(ketsu_segment, 2, get_key_func("çµ"))

    # æœ€çµ‚çš„ãªãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆæ¡ˆ
    playlist_draft = ki + sho + ten + ketsu
    
    # æœ€çµ‚çš„ã«æ™‚ç³»åˆ—ã§å†ã‚½ãƒ¼ãƒˆ
    try:
        playlist = sorted(playlist_draft, key=lambda x: datetime.strptime(x["timestamp"], '%Y-%m-%d %H:%M:%S') if x["timestamp"] else datetime.min)
    except:
        playlist = playlist_draft

    # --- Chapter Titles (ç‰©èªã¸ã®æ–‡å­—å…¥ã‚Œ) ---
    # èµ·ãƒ»æ‰¿ãƒ»è»¢ãƒ»çµã®å„é–‹å§‹ãƒã‚¤ãƒ³ãƒˆã«ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ä¸
    phase_titles = {
        "èµ·": "Chapter 1: The Beginning",
        "æ‰¿": "Chapter 2: Daily Life",
        "è»¢": "Chapter 3: Best Smiles",
        "çµ": "Chapter 4: Memories"
    }
    
    # å®Ÿéš›ã¯ vibe ãªã©ã«åˆã‚ã›ã¦æ—¥æœ¬èªã§æƒ…ç·’çš„ã«
    for i, clip in enumerate(playlist):
        tag = ""
        if clip in ki: tag = "èµ·"
        elif clip in sho: tag = "æ‰¿"
        elif clip in ten: tag = "è»¢"
        elif clip in ketsu: tag = "çµ"
        
        # å„ãƒ•ã‚§ãƒ¼ã‚ºã®æœ€åˆã®1ç§’é–“ï¼ˆã¾ãŸã¯ã‚¯ãƒªãƒƒãƒ—ï¼‰ã«è¡¨ç¤º
        if i == 0:
            clip["overlay_text"] = "The Story of " + person_name
        elif tag == "æ‰¿" and playlist[i-1] in ki:
            clip["overlay_text"] = "ç©ã‚„ã‹ãªæ—¥å¸¸"
        elif tag == "è»¢" and playlist[i-1] in sho:
            clip["overlay_text"] = "æœ€é«˜ã®ç¬‘é¡”"
        elif tag == "çµ" and playlist[i-1] in ten:
            clip["overlay_text"] = "ã„ã¤ã¾ã§ã‚‚ã€ã“ã®ç¬é–“ã‚’"

    # --- BGM Recommendation ---
    vibes = [c["vibe"] for c in playlist]
    vibe_counts = {v: vibes.count(v) for v in set(vibes)}
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚¯ãƒªãƒƒãƒ—ã‹ã‚‰ã®åˆ¤å®š
    dominant_vibe = max(vibe_counts, key=vibe_counts.get) if vibe_counts else "ç©ã‚„ã‹"

    # Focusã«ã‚ˆã‚‹å¼·åŠ›ãªã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
    if focus == "Smile": dominant_vibe = "ã‹ã‚ã„ã„"
    elif focus == "Active": dominant_vibe = "ã‚¨ãƒãƒ«ã‚®ãƒƒã‚·ãƒ¥"
    elif focus == "Emotional": dominant_vibe = "æ„Ÿå‹•çš„"
    elif focus == "Balance": dominant_vibe = "ç©ã‚„ã‹"

    bgm_map = {
        "ç©ã‚„ã‹": "Lo-fi / Acoustic (Soft and warm)",
        "ã‚¨ãƒãƒ«ã‚®ãƒƒã‚·ãƒ¥": "Upbeat / Pop (High energy and bright)",
        "æ„Ÿå‹•çš„": "Cinematic / Piano (Dramatic and emotional)",
        "ã‹ã‚ã„ã„": "Gentle Lofi / Nostalgic (Cute and relaxing)"
    }
    bgm_suggestion = bgm_map.get(dominant_vibe, "Lo-fi / Cinematic MIX")

    # --- Output ---
    print(f"\n========================================")
    print(f"ğŸ¬ 1-MINUTE DOCUMENTARY PLAN: {person_name}")
    print(f"========================================\n")
    
    print(f"ğŸµ SUGGESTED BGM: {bgm_suggestion}\n")
    
    print(f"ğŸ“‹ PLAYLIST (Total: {len(playlist)} clips, approx 60s):")
    print("(Chronologically ordered for a smooth narrative flow)\n")
    for i, clip in enumerate(playlist):
        # Find which phase the clip belongs to based on original segment lists
        phase = "?"
        if clip in ki: phase = "èµ·"
        elif clip in sho: phase = "æ‰¿"
        elif clip in ten: phase = "è»¢"
        elif clip in ketsu: phase = "çµ"
        
        print(f"[{phase}] {os.path.basename(clip['video_path'])} @ {clip['t']}s (Time: {clip['timestamp']}, Happy: {clip['happy']})")

    # Save playlist to a file for render_story to read
    playlist_data = {
        "person_name": person_name,
        "clips": playlist,
        "dominant_vibe": dominant_vibe,
        "suggested_bgm": bgm_suggestion
    }
    
    with open(output_playlist_path, 'w', encoding='utf-8') as f:
        json.dump(playlist_data, f, indent=4, ensure_ascii=False)
    
    print(f"\nPlaylist data saved to '{output_playlist_path}'")
    print(f"Dominant vibe: {dominant_vibe}")


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("person")
    parser.add_argument("--period", default="All Time")
    parser.add_argument("--focus", default="Balance")
    parser.add_argument("--bgm", action="store_true")
    parser.add_argument("--no-bgm", action="store_false", dest="bgm")
    args = parser.parse_args()

    create_story(args.person, period=args.period, focus=args.focus, bgm_enabled=args.bgm)
