import json
import os
import sys
import cv2
from datetime import datetime



from utils import get_user_data_dir

def load_scan_results(json_path='scan_results.json'):
    from utils import load_json_safe
    return load_json_safe(json_path, lambda: {"people": {}, "metadata": {}})

def main():
    # Unused main method, keeping for future script logic or CLI extension
    pass
def create_story(person_name, period="All Time", focus="Balance", bgm_enabled=False, json_path='scan_results.json', output_playlist_path='story_playlist.json', manual_bgm_path=""):
    print(f"DEBUG: create_story received manual_bgm_path = '{manual_bgm_path}'")
    results = load_scan_results(json_path)
    if not results or person_name not in results.get("people", {}):
        print(f"Error: No data found for {person_name}")
        return

    video_map = results["people"][person_name]
    metadata = results.get("metadata", {})
    all_clips = []
    valid_videos_cache = {} # èª­ã¿è¾¼ã¿å¯å¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥

    # Flatten the results into a list of clips with metadata
    for video_path, detections in video_map.items():
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Ÿåœ¨ã¨èª­ã¿è¾¼ã¿å¯å¦ã‚’ãƒã‚§ãƒƒã‚¯
        if video_path not in valid_videos_cache:
            if os.path.exists(video_path):
                # OpenCVã§ãƒ˜ãƒƒãƒ€ãƒ¼ãŒèª­ã¿è¾¼ã‚ã‚‹ã‹è©¦è¡Œ (I/Oã‚¨ãƒ©ãƒ¼å¯¾ç­–)
                cap = cv2.VideoCapture(video_path)
                if cap.isOpened():
                    valid_videos_cache[video_path] = True
                    cap.release()
                else:
                    print(f"  Warning: Video file exists but is unreadable (I/O error): {video_path}")
                    valid_videos_cache[video_path] = False
            else:
                valid_videos_cache[video_path] = False

        if not valid_videos_cache[video_path]:
            continue

        # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        month = metadata.get(video_path, {}).get('month', 'unknown')
        if period != "All Time":
            if period.count("-") == 1: # YYYY-MM
                if month != period: continue
            else: # YYYY
                if month.split("-")[0] != period: continue

        for det in detections:
            all_clips.append({
                "video_path": video_path,
                "t": det["t"],
                "happy": det.get("happy", 0),
                "visual_score": det.get("visual_score", 5.0),
                "vibe": det.get("vibe", "ç©ã‚„ã‹"),
                "drama": det.get("drama", 0),
                "motion": det.get("motion", 0),
                "face_ratio": det.get("face_ratio", 0),
                "timestamp": det.get("timestamp", ""),
                "overlay_text": "" # å¾Œã§è¿½åŠ 
            })

    if not all_clips:
        print(f"Error: No clips found for {person_name}")
        return

    # Sort by timestamp first
    try:
        all_clips.sort(key=lambda x: datetime.strptime(x["timestamp"], '%Y-%m-%d %H:%M:%S') if x["timestamp"] else datetime.min)
    except:
        pass

    # ã™ã§ã«ä½¿ã£ãŸã‚·ãƒ¼ãƒ³ã€å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã€æ—¥ä»˜ã‚’è¨˜éŒ²ã™ã‚‹
    used_scenes = set() # (video_path, t) ã‚’è¨˜éŒ²
    used_videos = set()
    used_dates = set()

    import random

    def pick_unique(candidates, count, key_func, reverse=True):
        """é‡è¤‡ã‚’é¿ã‘ã¤ã¤ã€ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³è±Šã‹ãªå€™è£œã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’è€ƒæ…®ã—ã¦é¸æŠã™ã‚‹ã€‚"""
        
        # ã‚¹ã‚³ã‚¢ã«æºã‚‰ãï¼ˆãƒã‚¤ã‚ºï¼‰ã‚’åŠ ãˆã‚‹
        def noisy_key(x):
            val = key_func(x)
            # ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å¯¾å¿œ (total_score, breakdown) ã®ã‚¿ãƒ—ãƒ«ãŒè¿”ã‚‹å ´åˆ
            if isinstance(val, tuple) and len(val) == 2 and isinstance(val[1], dict):
                total, breakdown = val
                x["_score_breakdown"] = breakdown
                x["_total_score"] = total
                return total * random.uniform(0.8, 1.2)
            
            # å¾“æ¥å½¢å¼ã®å ´åˆ
            # æ•°å€¤ã®å ´åˆã¯ Â±20% ã®æºã‚‰ãã‚’åŠ ãˆã‚‹
            if isinstance(val, (int, float)):
                return val * random.uniform(0.8, 1.2)
            # ã‚¿ãƒ—ãƒ«ã®å ´åˆã¯å„è¦ç´ ã« Â±10% ã®æºã‚‰ãï¼ˆæ•°å€¤ã®ã¿ï¼‰
            if isinstance(val, tuple):
                return tuple((v * random.uniform(0.9, 1.1) if isinstance(v, (int, float)) else v) for v in val)
            return val

        # æºã‚‰ãã‚’åŠ ãˆãŸã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        sorted_cands = sorted(candidates, key=noisy_key, reverse=reverse)
        
        # å€™è£œãƒ—ãƒ¼ãƒ«ã‚’å¤§å¹…ã«åºƒã’ã‚‹ï¼ˆå¿…è¦æ•°ã®15å€ã€ã¾ãŸã¯å…¨å€™è£œã®åŠåˆ†ï¼‰
        pool_size = max(min(len(sorted_cands), count * 15), len(sorted_cands) // 2)
        pool = sorted_cands[:pool_size]
        
        # çµ¶å¯¾ã«åŒã˜ã‚·ãƒ¼ãƒ³ã¯é¸ã°ãªã„ (STRICT)
        pool = [c for c in pool if (c["video_path"], c["t"]) not in used_scenes]
        
        picked = []
        
        # åŒä¸€å‹•ç”»å†…ã§ã®æ™‚é–“çš„åˆ†æ•£ï¼ˆè¿‘ãã®ã‚·ãƒ¼ãƒ³ã‚’é€£ç¶šã—ã¦é¸ã°ãªã„ï¼‰
        def is_temporally_dispersed(c):
            # åŒã˜å‹•ç”»ã‹ã‚‰æ—¢ã«é¸ã‚“ã§ã„ã‚‹å ´åˆã€ãã‚Œã‚‰ã¨ä¸€å®šæ™‚é–“(15ç§’)ä»¥ä¸Šé›¢ã‚Œã¦ã„ã‚‹ã‹
            picked_ts = [p["t"] for p in picked if p["video_path"] == c["video_path"]]
            # ä»–ã®ãƒ•ã‚§ãƒ¼ã‚ºã§é¸ã°ã‚ŒãŸã‚·ãƒ¼ãƒ³ã¨ã‚‚æ¯”è¼ƒ
            global_picked_ts = [s[1] for s in used_scenes if s[0] == c["video_path"]]
            all_nearby_ts = picked_ts + global_picked_ts
            
            for pt in all_nearby_ts:
                if abs(pt - c["t"]) < 15.0:
                    return False
            return True

        # Phase 1: æœªä½¿ç”¨ã®æ—¥ä»˜ & æœªä½¿ç”¨ã®ãƒ“ãƒ‡ã‚ª & æ™‚é–“çš„åˆ†æ•£
        p1 = [c for c in pool if c["video_path"] not in used_videos and c["timestamp"].split(" ")[0] not in used_dates and is_temporally_dispersed(c)]
        random.shuffle(p1)
        for c in p1:
            if len(picked) >= count: break
            picked.append(c)
            used_scenes.add((c["video_path"], c["t"]))
            used_videos.add(c["video_path"])
            used_dates.add(c["timestamp"].split(" ")[0])
        
        # Phase 2: æœªä½¿ç”¨ã®ãƒ“ãƒ‡ã‚ª & æ™‚é–“çš„åˆ†æ•£
        if len(picked) < count:
            p2 = [c for c in pool if c["video_path"] not in used_videos and (c["video_path"], c["t"]) not in used_scenes and is_temporally_dispersed(c)]
            random.shuffle(p2)
            for c in p2:
                if len(picked) >= count: break
                picked.append(c)
                used_scenes.add((c["video_path"], c["t"]))
                used_videos.add(c["video_path"])
                used_dates.add(c["timestamp"].split(" ")[0])

        # Phase 3: æ¡ä»¶ã‚’ç·©ã‚ã¦é¸ã¶ (ãŸã ã—ã‚·ãƒ¼ãƒ³é‡è¤‡ã¯çµ¶å¯¾ã«NG)
        if len(picked) < count:
            remaining = [c for c in pool if (c["video_path"], c["t"]) not in used_scenes]
            random.shuffle(remaining)
            for c in remaining:
                if len(picked) >= count: break
                picked.append(c)
                used_scenes.add((c["video_path"], c["t"]))
                        
        return picked

    # Focus ã®æ­£è¦åŒ– (UIã¯æ—¥æœ¬èªã€å†…éƒ¨ã¯è‹±èªã§åˆ¤å®šã—ã¦ã„ãŸãŸã‚)
    focus_map = {
        "ãƒãƒ©ãƒ³ã‚¹": "Balance",
        "ç¬‘é¡”": "Smile",
        "å‹•ã": "Active",
        "æ„Ÿå‹•": "Emotional"
    }
    focus = focus_map.get(focus, focus)

    # --- Step 0.5: çµ±è¨ˆæƒ…å ±ã®å‡ºåŠ› (å„Focusã¸ã®è©²å½“ä»¶æ•°ã‚’è¨ˆç®—) ---
    count_smile = len([c for c in all_clips if c["happy"] >= 0.5])
    count_emotional = len([c for c in all_clips if c["drama"] >= 0.5])
    count_active = len([c for c in all_clips if c["motion"] >= 3.0])
    
    print(f"\n--- ç´ æçµ±è¨ˆ (å…¨ {len(all_clips)} ã‚·ãƒ¼ãƒ³) ---")
    print(f"  ğŸ˜Š ç¬‘é¡” (Smile): {count_smile} ã‚·ãƒ¼ãƒ³")
    print(f"  ğŸ¬ æ„Ÿå‹• (Emotional): {count_emotional} ã‚·ãƒ¼ãƒ³")
    print(f"  âš¡ å‹•ã (Active): {count_active} ã‚·ãƒ¼ãƒ³")
    print(f"  âš–ï¸ å…¨ä½“ (Total): {len(all_clips)} ã‚·ãƒ¼ãƒ³")
    print(f"----------------------------------------\n")

    # --- Step 1: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é‡è¦–é …ç›®ï¼ˆFocusï¼‰ã«ã‚ˆã‚‹äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° ---
    filtered_clips = []
    if focus == "Smile":
        filtered_clips = [c for c in all_clips if c["happy"] >= 0.5]
        filter_msg = "ç¬‘é¡”ç‡ 50%ä»¥ä¸Š"
    elif focus == "Emotional":
        filtered_clips = [c for c in all_clips if c["drama"] >= 0.5]
        filter_msg = "ãƒ‰ãƒ©ãƒåº¦ 50%ä»¥ä¸Š"
    elif focus == "Active":
        filtered_clips = [c for c in all_clips if c["motion"] >= 3.0]
        filter_msg = "å‹•ã 3.0ä»¥ä¸Š"
    else: # Balance
        # ä»–ã®3ã¤ã®æ¡ä»¶ï¼ˆç¬‘é¡”ã€æ„Ÿå‹•ã€å‹•ãï¼‰ã®ã„ãšã‚Œã«ã‚‚è©²å½“ã—ãªã„ã€Œæ—¥å¸¸ã€ã‚·ãƒ¼ãƒ³ã‚’æŠ½å‡º
        filtered_clips = [c for c in all_clips if not (c["happy"] >= 0.5 or c["drama"] >= 0.5 or c["motion"] >= 3.0)]
        filter_msg = "æ—¥å¸¸ã‚·ãƒ¼ãƒ³ï¼ˆç‰¹å¾´çš„ãªã‚¯ãƒªãƒƒãƒ—ä»¥å¤–ï¼‰"

    # --- Step 1.5: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç† (ã‚¯ãƒªãƒƒãƒ—ãŒå°‘ãªã™ãã‚‹å ´åˆ) ---
    # Balance ã®å ´åˆã‚‚ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®çµæœå°‘ãªã™ãã‚Œã°å…¨ã‚¯ãƒªãƒƒãƒ—ã«æˆ»ã™
    if len(filtered_clips) < 20:
        print(f"  Warning: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ç´ æãŒ {len(filtered_clips)} ä»¶ã¨å°‘ãªã™ãã‚‹ãŸã‚ã€å…¨ã‚¯ãƒªãƒƒãƒ—ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        filtered_clips = all_clips
    elif focus != "Balance":
        print(f"  Info: '{filter_msg}' ã«ã‚ˆã‚Š {len(all_clips)} ä»¶ -> {len(filtered_clips)} ä»¶ã«çµã‚Šè¾¼ã¿ã¾ã—ãŸã€‚")
    else:
        print(f"  Info: 'ãƒãƒ©ãƒ³ã‚¹'è¨­å®šã«ã‚ˆã‚Šæ—¥å¸¸ã‚·ãƒ¼ãƒ³ï¼ˆ{len(filtered_clips)}ä»¶ï¼‰ã‚’å¯¾è±¡ã«ã—ã¾ã™ã€‚")

    # --- Step 2: çµã‚Šè¾¼ã¾ã‚ŒãŸãƒªã‚¹ãƒˆã‚’æ™‚ç³»åˆ—ã§å†è¨ˆç®—ã—ã€èµ·æ‰¿è»¢çµã«åˆ†å‰² ---
    total_count = len(filtered_clips)
    idx_ki = max(1, int(total_count * 0.2))
    idx_sho = max(idx_ki + 1, int(total_count * 0.65))
    idx_ten = max(idx_sho + 1, int(total_count * 0.9))

    ki_segment = filtered_clips[:idx_ki]
    sho_segment = filtered_clips[idx_ki:idx_sho]
    ten_segment = filtered_clips[idx_sho:idx_ten]
    ketsu_segment = filtered_clips[idx_ten:]

    # Focusã«å¿œã˜ãŸé¸æŠãƒ­ã‚¸ãƒƒã‚¯ (æ§‹é€  Ã— ã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°)
    def get_key_func(part):
        def score_clip(x):
            # 1. æ§‹é€ ã«ã‚ˆã‚‹ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢ (0.0 ~ 1.0)
            base = x.get("visual_score", 5.0) / 10.0
            
            # 2. æ§‹é€ ä¸Šã®å½¹å‰²ã«å¿œã˜ãŸé‡ã¿ä»˜ã‘
            struct_weight = 1.0
            if part == "èµ·":
                if x.get("vibe") != "ç©ã‚„ã‹": struct_weight *= 0.3
            elif part == "çµ":
                ratio = x.get("face_ratio", 1.0)
                if ratio > 3.0: struct_weight *= 1.5
                if x.get("vibe") != "ç©ã‚„ã‹": struct_weight *= 0.5

            # 3. Focus Style ã«ã‚ˆã‚‹åŠ ç‚¹ (ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ã ãŒã€ãã®ä¸­ã§ã‚‚ã‚ˆã‚Šè‰¯ã„ã‚‚ã®ã‚’é¸ã¶)
            style_bonus = 0.0
            if focus == "Balance":
                # ãƒãƒ©ãƒ³ã‚¹ã®å ´åˆã¯ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã›ãšä¸€å¾‹ï¼ˆnoisy_keyã«ã‚ˆã‚Šå®Ÿè³ªãƒ©ãƒ³ãƒ€ãƒ é¸æŠï¼‰
                style_bonus = 1.0
            elif focus == "Smile":
                style_bonus = x.get("happy", 0) * 2.0
            elif focus == "Active":
                style_bonus = (x.get("motion", 0) / 5.0)
            elif focus == "Emotional":
                style_bonus = x.get("drama", 0) + (x.get("face_ratio", 0) / 10.0)
            else:
                # äºˆå‚™
                style_bonus = (x.get("happy", 0) + x.get("drama", 0) + (x.get("motion", 0)/10.0)) / 1.5

            total_score = (base * struct_weight) + style_bonus
            return total_score, {
                "base": round(base, 2),
                "struct": round(struct_weight, 2),
                "style": round(style_bonus, 2)
            }
        return score_clip

    # [èµ·] Intro: 2 clips
    ki = pick_unique(ki_segment, 2, get_key_func("èµ·"))
    # [æ‰¿] Development: 10 clips
    sho = pick_unique(sho_segment, 10, get_key_func("æ‰¿"))
    # [è»¢] Twist/Climax: 6 clips
    ten = pick_unique(ten_segment, 6, get_key_func("è»¢"))
    # [çµ] Conclusion: 2 clips
    ketsu = pick_unique(ketsu_segment, 2, get_key_func("çµ"))

    # æœ€çµ‚çš„ãªãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆæ¡ˆ
    playlist_draft = ki + sho + ten + ketsu
    
    # æœ€çµ‚çš„ã«æ™‚ç³»åˆ—ã§å†ã‚½ãƒ¼ãƒˆ
    try:
        playlist = sorted(playlist_draft, key=lambda x: datetime.strptime(x["timestamp"], '%Y-%m-%d %H:%M:%S') if x["timestamp"] else datetime.min)
    except:
        playlist = playlist_draft

    # --- Chapter Titles (ç‰©èªã¸ã®æ–‡å­—å…¥ã‚Œ) ---
    # èµ·ãƒ»æ‰¿ãƒ»è»¢ãƒ»çµã®å„é–‹å§‹ãƒã‚¤ãƒ³ãƒˆã«ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ä¸
    phase_titles = {
        "èµ·": "Chapter 1: The Beginning",
        "æ‰¿": "Chapter 2: Daily Life",
        "è»¢": "Chapter 3: Best Smiles",
        "çµ": "Chapter 4: Memories"
    }
    
    # å®Ÿéš›ã¯ vibe ãªã©ã«åˆã‚ã›ã¦æ—¥æœ¬èªã§æƒ…ç·’çš„ã«
    for i, clip in enumerate(playlist):
        tag = ""
        if clip in ki: tag = "èµ·"
        elif clip in sho: tag = "æ‰¿"
        elif clip in ten: tag = "è»¢"
        elif clip in ketsu: tag = "çµ"
        
        # å„ãƒ•ã‚§ãƒ¼ã‚ºã®æœ€åˆã®1ç§’é–“ï¼ˆã¾ãŸã¯ã‚¯ãƒªãƒƒãƒ—ï¼‰ã«è¡¨ç¤º
        if i == 0:
            clip["overlay_text"] = "The Story of " + person_name
        elif tag == "æ‰¿" and playlist[i-1] in ki:
            clip["overlay_text"] = "ç©ã‚„ã‹ãªæ—¥å¸¸"
        elif tag == "è»¢" and playlist[i-1] in sho:
            clip["overlay_text"] = "æœ€é«˜ã®ç¬‘é¡”"
        elif tag == "çµ" and playlist[i-1] in ten:
            clip["overlay_text"] = "ã„ã¤ã¾ã§ã‚‚ã€ã“ã®ç¬é–“ã‚’"

    # --- BGM Recommendation ---
    # Automatic BGM selection is removed. Only manual selection is used.
    dominant_vibe = "None (Auto-selection removed)"
    bgm_suggestion = "Manual Selection Only"

    # --- Output ---
    print(f"\n========================================")
    print(f"ğŸ¬ 1-MINUTE DOCUMENTARY PLAN: {person_name}")
    print(f"========================================\n")
    
    print(f"ğŸµ SUGGESTED BGM: {bgm_suggestion}\n")
    
    print(f"ğŸ“‹ PLAYLIST (Total: {len(playlist)} clips, approx 60s):")
    print("(Chronologically ordered for a smooth narrative flow)\n")
    for i, clip in enumerate(playlist):
        # Find which phase the clip belongs to based on original segment lists
        phase = "?"
        if clip in ki: phase = "èµ·"
        elif clip in sho: phase = "æ‰¿"
        elif clip in ten: phase = "è»¢"
        elif clip in ketsu: phase = "çµ"
        
        print(f"[{phase}] {os.path.basename(clip['video_path'])} @ {clip['t']}s (Time: {clip['timestamp']}, Happy: {clip['happy']})")

    # Save playlist to a file for render_story to read
    playlist_data = {
        "person_name": person_name,
        "clips": playlist,
        "dominant_vibe": dominant_vibe,
        "suggested_bgm": bgm_suggestion,
        "manual_bgm_path": manual_bgm_path
    }
    
    with open(output_playlist_path, 'w', encoding='utf-8') as f:
        json.dump(playlist_data, f, indent=4, ensure_ascii=False)
    
    print(f"\nPlaylist data saved to '{output_playlist_path}'")
    print(f"Dominant vibe: {dominant_vibe}")


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("person")
    parser.add_argument("--period", default="All Time")
    parser.add_argument("--focus", default="Balance")
    parser.add_argument("--bgm", action="store_true")
    parser.add_argument("--no-bgm", action="store_false", dest="bgm")
    args = parser.parse_args()

    create_story(args.person, period=args.period, focus=args.focus, bgm_enabled=args.bgm)
