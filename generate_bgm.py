import torch

# Monkey patch for systems without xpu support to avoid AttributeError
if not hasattr(torch, "xpu"):
    class DummyXPU:
        def is_available(self):
            return False
        def empty_cache(self):
            pass
        def device_count(self):
            return 0
        def current_device(self):
            return "cpu"
        def synchronize(self):
            pass
        def __getattr__(self, name):
            # Fallback for any other attribute to prevent crash
            def method(*args, **kwargs):
                return None
            return method
    torch.xpu = DummyXPU()

import torch.distributed
if not hasattr(torch.distributed, "device_mesh"):
    class DummyDeviceMeshModule:
        class DeviceMesh:
            def __init__(self, *args, **kwargs):
                pass
    torch.distributed.device_mesh = DummyDeviceMeshModule()

import os

import scipy.io.wavfile as wavfile
import numpy as np
from datetime import datetime

# Stable Audio Open 1.0 ã¯ diffusers ã‚’ä½¿ç”¨ã—ã¾ã™
# Note: ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯GatedãªãŸã‚ã€é…å¸ƒæ™‚ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«HFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›ã—ã¦ã‚‚ã‚‰ã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

def generate_bgm(vibe="ç©ã‚„ã‹", duration_seconds=30, output_dir="bgm", token=None):
    """
    Stable Audio Open 1.0 ã‚’ä½¿ç”¨ã—ã¦BGMã‚’ç”Ÿæˆã—ã€WAVã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚
    """
    from diffusers import StableAudioPipeline
    
    import random
    
# Vibeã‚’è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒªã‚¹ãƒˆã«ãƒãƒƒãƒ”ãƒ³ã‚° (ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åˆ·æ–°)
VIBE_PROMPTS_MAP = {
    "ç©ã‚„ã‹": [
        "Format: Solo. Instrument: Grand Piano. Genre: Minimalist Classical, Neoclassical. Mood: Peaceful, Harmonious, Consonant, Serene, Uplifting. Details: High fidelity, studio recording, pristine sound, clear melody, simple arrangement, lyrical phrasing, reverb. BPM: 80."
    ],
    "ã‚¨ãƒãƒ«ã‚®ãƒƒã‚·ãƒ¥": [
        "Format: Instrumental. Genre: Corporate, Easy Listening. Instruments: Bright Grand Piano lead. Mood: Motivational, Inspiring, Positive, Success, Optimistic. Style: Advertising, Commercial, Podcast Intro. Details: Clean mix, balanced, simple melody, catchy hook, rhythmic but harmonious. BPM: 110."
    ],
    "æ„Ÿå‹•çš„": [
        "Format: Solo. Instrument: Steinway Grand Piano. Genre: Cinematic, Pop Ballad. Mood: Emotional, Heartfelt, Hopeful, Euphoric, Touching. Style: Movie Soundtrack, Film Score. Details: Featured melody, expressive performance, dynamic, well-arranged, harmonious, lush reverb. BPM: 90."
    ],
    "ã‹ã‚ã„ã„": [
        "Children's Music, Kawaii, Upright Piano, Toy Piano, Cute, Playful, Whimsical, 110 BPM, C Major, High Octave, Simple Melody, Bouncy, Crisp, Dry Mix, Seamless Loop" 
    ]
}

# Default negative prompt to exclude drums/percussion/jazz/dissonance
DEFAULT_NEGATIVE_PROMPT = "Drums, Percussion, Jazz, Dissonance, Atonal, Complex, Muddy, low quality, noise"

def generate_bgm(vibe="ç©ã‚„ã‹", duration_seconds=30, output_dir="bgm", token=None, prompt_index=None, num_inference_steps=50, negative_prompt=None):
    """
    Stable Audio Open 1.0 ã‚’ä½¿ç”¨ã—ã¦BGMã‚’ç”Ÿæˆã—ã€WAVã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚
    """
    from diffusers import StableAudioPipeline
    
    import random
    
    choices = VIBE_PROMPTS_MAP.get(vibe, VIBE_PROMPTS_MAP["ç©ã‚„ã‹"])
    if prompt_index is not None and 0 <= prompt_index < len(choices):
        idx = prompt_index
    else:
        idx = random.randint(0, len(choices) - 1)
    prompt = choices[idx]
    
    # Use default negative prompt if none provided
    if negative_prompt is None:
        negative_prompt = DEFAULT_NEGATIVE_PROMPT
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸€éƒ¨ã‚’æŠœç²‹ã—ã¦ã‚¹ã‚¿ã‚¤ãƒ«åã¨ã—ã¦ä½¿ç”¨ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åç”¨ï¼‰
    style_keywords = ["piano", "guitar", "synth", "violin", "lofi", "8-bit", "orchestra", "ambient"]
    detected_style = "music"
    for kw in style_keywords:
        if kw in prompt.lower():
            detected_style = kw
            break

    # Vibeã«å¿œã˜ãŸãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«å (ç•ªå· _P1, _P2 ãªã©ã‚’å«ã‚ã‚‹)
    base_name = vibe
    p_tag = f"_P{idx+1}"
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{base_name}{p_tag}_{timestamp}.wav"
    
    # Ensure absolute path if it looks relative
    if not os.path.isabs(output_dir):
        from utils import get_app_dir
        output_dir = os.path.join(get_app_dir(), output_dir)
        
    os.makedirs(output_dir, exist_ok=True)
        
    output_path = os.path.join(output_dir, filename)

    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, filename)

    # Stable Audio Open 1.0 ã¯æœ€å¤§47ç§’ã¾ã§å¯¾å¿œ
    # 47ç§’ã‚’è¶…ãˆã‚‹å‹•ç”»ï¼ˆä¾‹: 67ç§’ï¼‰ã®å ´åˆã€åŠåˆ†ã®é•·ã•ï¼ˆ33.5ç§’ï¼‰ã‚’2å›ãƒ«ãƒ¼ãƒ—ã•ã›ã‚‹æ–¹ãŒ
    # 1ã¤ã®é•·ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æœ«å°¾ã§ç„¡ç†ã‚„ã‚Šç¹‹ãã‚ˆã‚ŠéŸ³æ¥½çš„ã«è‡ªç„¶ã«ãªã‚Šã‚„ã™ã„ã€‚
    is_looped = False
    if duration_seconds > 47.0:
        audio_duration = duration_seconds / 2.0
        is_looped = True
    else:
        audio_duration = min(duration_seconds, 47.0)

    print(f"\n" + "="*50)
    print(f"ğŸ¬ AI BGM GENERATION: {vibe}")
    print(f"="*50)
    print(f"  - Style:    {detected_style}")
    if is_looped:
        print(f"  - Length:   {duration_seconds}s -> {audio_duration:.1f}s (Loop-optimized)")
    else:
        print(f"  - Length:   {audio_duration:.1f}s (Model Limit: 47s)")
    print(f"  - Output:   {os.path.basename(output_path)}")
    print(f"  - Prompt:   {prompt}")
    if negative_prompt:
        print(f"  - Negative: {negative_prompt}")
    print(f"-"*50)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    # Mac M1/M2/M3 ã®å ´åˆã¯ mps ã‚’å„ªå…ˆ
    if torch.backends.mps.is_available():
        device = "mps"
    
    # mps ã¯ float16 ã¾ãŸã¯ float32
    dtype = torch.float16 if device != "cpu" else torch.float32
    
    try:
        print(f"  ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­... ({device}, {dtype})")
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
        # token ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
        pipe = StableAudioPipeline.from_pretrained(
            "stabilityai/stable-audio-open-1.0", 
            torch_dtype=dtype,
            token=token
        )
        pipe = pipe.to(device)

        # Use EulerDiscreteScheduler for stability
        from diffusers import EulerDiscreteScheduler
        pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)
        
        # ç”Ÿæˆ
        print(f"  éŸ³æ¥½ã‚’ç”Ÿæˆä¸­...")
        # ç”Ÿæˆå®Ÿè¡Œ
        output = pipe(
            prompt, 
            negative_prompt=negative_prompt,
            num_inference_steps=num_inference_steps, 
            audio_end_in_s=audio_duration
        ).audios
        print() # Force newline after tqdm progress bar
        
        # output[0] ã¯ç¬¬ä¸€ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ« (channels, samples)
        # scipy.io.wavfile.write ã®ãŸã‚ã« NumPy é…åˆ—ã«å¤‰æ›
        audio_data = output[0]
        if hasattr(audio_data, "cpu"):
            audio_data = audio_data.cpu().numpy()
        elif hasattr(audio_data, "numpy"):
            audio_data = audio_data.numpy()
        
        # 44.1kHz ã§ä¿å­˜
        # scipy.io.wavfile.write ã¯ float16 ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ãŸã‚ float32 ã«å¤‰æ›
        # ã¾ãŸã€(samples, channels) ã‚’æœŸå¾…ã™ã‚‹ãŸã‚è»¢ç½®
        audio_data_t = audio_data.T.astype(np.float32)
        
        wavfile.write(output_path, 44100, audio_data_t)
        
        print(f">>> BGMç”Ÿæˆå®Œäº†: {output_path}")
        return True, output_path
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"Error during BGM generation: {e}")
        if "gated" in str(e).lower() or "not found" in str(e).lower() or "unauthorized" in str(e).lower():
            print("ãƒ’ãƒ³ãƒˆ: ã“ã®ãƒ¢ãƒ‡ãƒ«ã«ã¯ Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¿…è¦ã§ã™ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return False, None

if __name__ == "__main__":
    import sys
    test_token = os.getenv("HF_TOKEN")
    success, _ = generate_bgm(vibe="ç©ã‚„ã‹", duration_seconds=10, token=test_token)
    sys.exit(0 if success else 1)
